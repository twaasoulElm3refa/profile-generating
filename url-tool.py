import requests
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from fastapi import FastAPI, Query, HTTPException
from database import fetch_profile_data ,insert_generated_profile
from pydantic import BaseModel
#from typing import Optional
from fastapi.responses import FileResponse
import os
from dotenv import load_dotenv
import json
from openai import OpenAI
import time
import openai 

# ØªØ­Ù…ÙŠÙ„ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
app = FastAPI()
#api_key=os.getenv("OPENAI_API_KEY")

origins = [
    "https://11ai.ellevensa.com",  # Replace with your WordPress site domain
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # Allows specific origins to make requests
    allow_credentials=True,
    allow_methods=["GET", "POST"],  # Allows specific methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers (or specify as needed)
)

# Function to call the OpenAI API and handle rate limit errors
def call_openai_api_with_retry(examples , data: str ,retries: int = 3, backoff: int = 5):
    client = OpenAI(api_key=api_key)
    examples_text = "\n\n".join(examples[:2])  # Ù†Ø±Ø³Ù„ Ø£ÙˆÙ„ Ù…Ø«Ø§Ù„ÙŠÙ† ÙÙ‚Ø· Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø·ÙˆÙ„
    prompt=f""" Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…Ø­ØªØ±Ù ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙÙŠØ© Ù„Ù„Ø´Ø±ÙƒØ§Øª (Company Profiles)ØŒ ÙˆØªØ¹Ù…Ù„ ÙƒÙ…Ø³ØªØ´Ø§Ø± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø¤Ø³Ø³ÙŠØ© ÙˆØµÙŠØ§ØºØ© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ
        Ø³ØªØªÙ„Ù‚Ù‰:
        - Ø£Ù…Ø«Ù„Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù„Ù…Ù„ÙØ§Øª ØªØ¹Ø±ÙŠÙÙŠØ© Ù†Ø§Ø¬Ø­Ø© Ù„Ø¹Ø¯Ø© Ø´Ø±ÙƒØ§Øª:
        {examples_text}
        
        ÙˆÙ…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬Ù‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©Ù‹ Ù…Ù† Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø´Ø±ÙƒØ© (URL):
        {data}
        ---
        
        ğŸ“Œ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ù†Ùƒ:
        1ï¸âƒ£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ÙˆØ§Ø±Ø¯Ø© Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙÙŠ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙÙŠØ©.
        2ï¸âƒ£ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© Ù…Ù† Ø§Ù„Ù…ÙˆÙ‚Ø¹ (url) ÙƒÙ…Ø§ Ù‡ÙŠ ØªÙ…Ø§Ù…Ù‹Ø§ØŒ ÙˆØ¥Ù† Ù„Ù… ØªÙƒÙ† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ÙƒØªÙ…Ù„Ø©Ø› Ù‚Ù… Ø¨Ø¥ÙƒÙ…Ø§Ù„Ù‡Ø§ ÙˆØ§Ø¨ØªÙƒØ§Ø± Ù…Ø­ØªÙˆÙ‰ Ù…ÙƒÙ…Ù„ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…ØªÙ†Ø§Ø³Ù‚.
        3ï¸âƒ£ ÙƒØªØ§Ø¨Ø© Ù…Ù„Ù ØªØ¹Ø±ÙŠÙÙŠ Ù…ØªÙƒØ§Ù…Ù„ ÙŠØ´Ù…Ù„:
           - Ù…Ù† Ù†Ø­Ù†
           - Ø§Ù„Ø±Ø¤ÙŠØ© (ÙÙŠ ÙÙ‚Ø±Ø© Ù…Ù†ÙØµÙ„Ø©)
           - Ø§Ù„Ø±Ø³Ø§Ù„Ø© (ÙÙŠ ÙÙ‚Ø±Ø© Ù…Ù†ÙØµÙ„Ø©)
           - Ù…Ø§ Ø§Ù„Ø°ÙŠ Ù†ÙÙ‚Ø¯Ù…Ù‡
           - Ù„Ù…Ø§Ø°Ø§ Ù†Ø­Ù†
           - Ø£Ø¹Ù…Ø§Ù„Ù†Ø§
           - Ø®Ø¯Ù…Ø§ØªÙ†Ø§ (Ù…ÙØµÙ„Ø© Ø¨Ù†Ù‚Ø§Ø·)
           - Ø£Ø³Ù„ÙˆØ¨Ù†Ø§
           - Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„
        
        ---
        
        âœ… ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©:
        - Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ù„ÙˆØ¨ Ø¹ØµØ±ÙŠ ÙˆØ¬Ø°Ø§Ø¨ ÙŠÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠ ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠ.
        - Ù„Ø§ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù‡ÙŠÙƒÙ„ Ø¬Ø§Ù‡Ø² Ø­Ø±ÙÙŠÙ‹Ø§Ø› Ø§Ø¨ØªÙƒØ± ØªØ±ØªÙŠØ¨Ù‹Ø§ ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ ÙŠÙ†Ø§Ø³Ø¨ Ù…Ø¬Ø§Ù„ Ø§Ù„Ø´Ø±ÙƒØ©.
        - Ø§Ø¬Ø¹Ù„ Ø§Ù„Ù†Øµ ØºÙ†ÙŠÙ‹Ø§ Ø¨Ø§Ù„ØªÙØ§ØµÙŠÙ„ ÙˆÙŠØ¹ÙƒØ³ Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„ØªÙ†Ø§ÙØ³ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ù„ØµØ© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø©.
        - Ø§Ø³ØªØ®Ø¯Ù… Ù„ØºØ© Ù…Ø¤Ø³Ø³ÙŠØ© Ø³Ù„Ø³Ø© ÙˆÙ…ØªÙ…Ø§Ø³ÙƒØ© Ø¨ØµØ±ÙŠÙ‹Ø§ ÙˆÙ…Ø¶Ù…ÙˆÙ†ÙŠÙ‹Ø§.
        - Ø§ÙØªØ±Ø¶ Ø£Ù† Ø§Ù„Ù…Ù„Ù Ø³ÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ù„Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ÙØ§Ø®Ø±Ø© ÙˆØ§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ© ÙˆØ§Ù„ØªÙ‚Ø¯ÙŠÙ…ÙŠØ©.
        - Ø§Ù„Ù…Ù„Ù ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙØ¬Ø³Ù‘Ø¯ Ù‡ÙˆÙŠØ© Ø§Ù„Ø´Ø±ÙƒØ© ÙˆÙŠÙ‚Ù†Ø¹ Ø§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±ÙŠØ© ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Ø¡ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙÙŠÙ†.
        
        ---
        
        âœ¨ Ø§Ù„Ù‡Ø¯Ù:
        Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù ØªØ¹Ø±ÙŠÙÙŠ Ù‚ÙˆÙŠ ÙŠØ¹Ø¨Ø± Ø¹Ù† Ø±ÙˆØ­ Ø§Ù„Ø´Ø±ÙƒØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…Ø³ØªÙˆØ­Ù‰ ÙˆÙ…ØªØ¹Ù„Ù‘ÙÙ… Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„ÙˆØ§Ø±Ø¯Ø©ØŒ Ù…Ø¹ Ù…Ù„Ø¡ Ø£ÙŠ Ù†Ù‚Øµ ÙÙŠ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹ ØªÙ„Ù‚Ø§Ø¦ÙŠÙ‹Ø§ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø§Ø­ØªØ±Ø§ÙÙŠ.
        """
    for i in range(retries):
        try:
            response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            )
            return response
        except openai.error.RateLimitError as e:
            if i < retries - 1:
                wait_time = backoff * (i + 1)  # Exponential backoff
                print(f"Rate limit exceeded. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)  # Wait before retrying
            else:
                raise HTTPException(status_code=429, detail="Rate limit exceeded, please try again later.")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e)) 

def extract_info_from_url_and_subpages(base_url, max_pages=7):
    visited = set()
    to_visit = [base_url]
    all_texts = []

    while to_visit and len(visited) < max_pages:
        url = to_visit.pop(0)
        if url in visited:
            continue
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            html = response.text
            soup = BeautifulSoup(html, "html.parser")

            visited.add(url)

            # Ø¬Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ
            page_text = []

            # Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
            title = soup.title.string.strip() if soup.title and soup.title.string else ""
            if title:
                page_text.append(f"Title: {title}")

            # meta description
            desc_tag = soup.find("meta", attrs={"name": "description"})
            if desc_tag and desc_tag.get("content"):
                page_text.append(f"Description: {desc_tag['content'].strip()}")

            # Ø£ÙˆÙ„ ÙÙ‚Ø±ØªÙŠÙ† Ø·ÙˆÙŠÙ„ØªÙŠÙ†
            paragraphs = soup.find_all("p")
            count = 0
            for p in paragraphs:
                text = p.get_text(strip=True)
                if len(text) > 50:
                    page_text.append(text)
                    count += 1
                if count >= 2:
                    break

            all_texts.append("\n".join(page_text))

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±ÙˆØ§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø²ÙŠØ§Ø±ØªÙ‡Ø§ Ù„Ø§Ø­Ù‚Ù‹Ø§
            for link in soup.find_all("a", href=True):
                href = link["href"]
                joined_url = urljoin(base_url, href)
                parsed_base = urlparse(base_url)
                parsed_joined = urlparse(joined_url)
                # Ù†ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø¯Ø§Ø®Ù„ÙŠ (Ù†ÙØ³ Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ†)
                if parsed_base.netloc == parsed_joined.netloc:
                    if joined_url not in visited and joined_url not in to_visit:
                        to_visit.append(joined_url)

        except Exception as e:
            print(f"âŒ Error visiting {url}: {e}")
            continue

    # Ø¯Ù…Ø¬ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    combined_text = "\n\n---\n\n".join(all_texts)
    return combined_text


def load_examples_from_json(json_path="example_profiles.json"):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)

@app.get("/profile-url/{user_id}/")
def profile_from_url(user_id: int,url: str = Query(..., description="Company website URL") ):
    #try:
    if not url or not url.startswith("http"):
        raise HTTPException(status_code=400, detail="Invalid URL")
    print (user_id, url)
    # Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·
    extracted_data = extract_info_from_url_and_subpages(url)

    # Ù†Ù‚Ø±Ø£ Ø§Ù„Ø£Ù…Ø«Ù„Ø©
    loaded_examples = load_examples_from_json()

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨Ø±ÙˆÙØ§ÙŠÙ„
    #generated_profile = generate_profile_model(extracted_data, loaded_examples)
    #print(generated_profile)

    try:
        #response = call_openai_api_with_retry(extracted_data,loaded_examples)
        #generated_profile = response.choices[0].message.content
        generated_profile = extracted_data
        input_type='Using URL'
        #  ØªØ­ÙØ¸Ù‡ ÙÙŠ db 
        save_data= insert_generated_profile(user_id,None,generated_profile,input_type)
        return {"profile": generated_profile}
    except HTTPException as e:
        raise e  # Forward HTTPException errors (e.g., rate limits)
    




