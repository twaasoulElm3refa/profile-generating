import requests
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
from fastapi import FastAPI, Query, HTTPException
from database import fetch_profile_data ,insert_generated_profile
#from pydantic import BaseModel
#from typing import Optional
from fastapi.responses import FileResponse
import os
from dotenv import load_dotenv
import json
from openai import OpenAI
import time
import openai 

# ุชุญููู ูุชุบูุฑุงุช ุงูุจูุฆุฉ
load_dotenv()
app = FastAPI()
api_key=os.getenv("OPENAI_API_KEY")

origins = [
    "https://11ai.ellevensa.com",  # Replace with your WordPress site domain
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # Allows specific origins to make requests
    allow_credentials=True,
    allow_methods=["GET", "POST"],  # Allows specific methods (GET, POST, etc.)
    allow_headers=["*"],  # Allows all headers (or specify as needed)
)

# Function to call the OpenAI API and handle rate limit errors
def call_openai_api_with_retry(examples , data: str ,retries: int = 3, backoff: int = 5):
client = OpenAI(api_key=api_key)
examples_text = "\n\n".join(examples[:2])  # ูุฑุณู ุฃูู ูุซุงููู ููุท ูุชูููู ุงูุทูู
prompt=f"""
    ุฃูุช ุฎุจูุฑ ูุญุชุฑู ูู ุฅุนุฏุงุฏ ุงููููุงุช ุงูุชุนุฑูููุฉ ููุดุฑูุงุช (Company Profiles)ุ ูุชุนูู ููุณุชุดุงุฑ ุงุณุชุฑุงุชูุฌู ูุชุทููุฑ ุงููููุฉ ุงููุคุณุณูุฉ ูุตูุงุบุฉ ุงููุญุชูู ุงูุชุณูููู ุงูุงุญุชุฑุงูู.
    
    ุณุชุชููู:
    - ุฃูุซูุฉ ุญููููุฉ ููููุงุช ุชุนุฑูููุฉ ูุงุฌุญุฉ ูุนุฏุฉ ุดุฑูุงุช:
    {examples_text}
    
    ููุนูููุงุช ุฃุณุงุณูุฉ ุชู ุงุณุชุฎุฑุงุฌูุง ูุจุงุดุฑุฉู ูู ูููุน ุงูุดุฑูุฉ (URL):
    {data}
    
    ---
    
    ๐ ุงููุทููุจ ููู:
    1๏ธโฃ ุชุญููู ุงูุฃูุซูุฉ ุงููุงุฑุฏุฉ ูุงุณุชุฎูุงุต ุฃุณููุจ ุงุญุชุฑุงูู ูุชูุงูู ูู ูุชุงุจุฉ ุงููููุงุช ุงูุชุนุฑูููุฉ.
    2๏ธโฃ ุงูุงุณุชูุงุฏุฉ ูู ุงูุจูุงูุงุช ุงููุณุชุฎุฑุฌุฉ ูู ุงููููุน (url) ููุง ูู ุชูุงููุงุ ูุฅู ูู ุชูู ุงููุนูููุงุช ููุชููุฉุ ูู ุจุฅููุงููุง ูุงุจุชูุงุฑ ูุญุชูู ูููู ุจุฃุณููุจ ูุชูุงุณู.
    3๏ธโฃ ูุชุงุจุฉ ููู ุชุนุฑููู ูุชูุงูู ูุดูู:
       - ูู ูุญู
       - ุงูุฑุคูุฉ (ูู ููุฑุฉ ูููุตูุฉ)
       - ุงูุฑุณุงูุฉ (ูู ููุฑุฉ ูููุตูุฉ)
       - ูุง ุงูุฐู ูููุฏูู
       - ููุงุฐุง ูุญู
       - ุฃุนูุงููุง
       - ุฎุฏูุงุชูุง (ููุตูุฉ ุจููุงุท)
       - ุฃุณููุจูุง
       - ูุนูููุงุช ุงูุชูุงุตู
    
    ---
    
    โ ุชุนูููุงุช ุฃุณุงุณูุฉ:
    - ุงุณุชุฎุฏู ุฃุณููุจ ุนุตุฑู ูุฌุฐุงุจ ููุงุฒู ุจูู ุงููุต ุงูุชุณูููู ูุงููุนูููุงุชู.
    - ูุง ุชุนุชูุฏ ุนูู ูููู ุฌุงูุฒ ุญุฑูููุงุ ุงุจุชูุฑ ุชุฑุชูุจูุง ุชุฏุฑูุฌููุง ููุงุณุจ ูุฌุงู ุงูุดุฑูุฉ.
    - ุงุฌุนู ุงููุต ุบูููุง ุจุงูุชูุงุตูู ููุนูุณ ุงููููุฉ ุงูุชูุงูุณูุฉ ุงููุณุชุฎูุตุฉ ูู ุงูุฃูุซูุฉ.
    - ุงุณุชุฎุฏู ูุบุฉ ูุคุณุณูุฉ ุณูุณุฉ ููุชูุงุณูุฉ ุจุตุฑููุง ููุถูููููุง.
    - ุงูุชุฑุถ ุฃู ุงูููู ุณููุณุชุฎุฏู ููุทุจุงุนุฉ ุงููุงุฎุฑุฉ ูุงูุนุฑูุถ ุงูุฅููุชุฑูููุฉ ูุงูุชูุฏูููุฉ.
    - ุงูููู ูุฌุจ ุฃู ููุฌุณูุฏ ูููุฉ ุงูุดุฑูุฉ ููููุน ุงูุฌูุงุช ุงูุงุณุชุซูุงุฑูุฉ ูุงูุนููุงุก ุงููุณุชูุฏููู.
    
    ---
    
    โจ ุงููุฏู:
    ุฅูุดุงุก ููู ุชุนุฑููู ููู ูุนุจุฑ ุนู ุฑูุญ ุงูุดุฑูุฉ ุจุฃุณููุจ ูุณุชูุญู ููุชุนูููู ูู ุงูุฃูุซูุฉ ุงููุงุฑุฏุฉุ ูุน ููุก ุฃู ููุต ูู ุจูุงูุงุช ุงููููุน ุชููุงุฆููุง ุจุฃุณููุจ ุงุญุชุฑุงูู.
    """
    for i in range(retries):
        try:
            response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=150
            )
            return response
        except openai.error.RateLimitError as e:
            if i < retries - 1:
                wait_time = backoff * (i + 1)  # Exponential backoff
                print(f"Rate limit exceeded. Retrying in {wait_time} seconds...")
                time.sleep(wait_time)  # Wait before retrying
            else:
                raise HTTPException(status_code=429, detail="Rate limit exceeded, please try again later.")
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e)) 

def extract_info_from_url_and_subpages(base_url, max_pages=5):
    visited = set()
    to_visit = [base_url]
    all_texts = []

    while to_visit and len(visited) < max_pages:
        url = to_visit.pop(0)
        if url in visited:
            continue
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            html = response.text
            soup = BeautifulSoup(html, "html.parser")

            visited.add(url)

            # ุฌูุน ุงููุตูุต
            page_text = []

            # ุงูุนููุงู
            title = soup.title.string.strip() if soup.title and soup.title.string else ""
            if title:
                page_text.append(f"Title: {title}")

            # meta description
            desc_tag = soup.find("meta", attrs={"name": "description"})
            if desc_tag and desc_tag.get("content"):
                page_text.append(f"Description: {desc_tag['content'].strip()}")

            # ุฃูู ููุฑุชูู ุทูููุชูู
            paragraphs = soup.find_all("p")
            count = 0
            for p in paragraphs:
                text = p.get_text(strip=True)
                if len(text) > 50:
                    page_text.append(text)
                    count += 1
                if count >= 2:
                    break

            all_texts.append("\n".join(page_text))

            # ุงุณุชุฎุฑุงุฌ ุฑูุงุจุท ุฏุงุฎููุฉ ุฌุฏูุฏุฉ ูุฒูุงุฑุชูุง ูุงุญููุง
            for link in soup.find_all("a", href=True):
                href = link["href"]
                joined_url = urljoin(base_url, href)
                parsed_base = urlparse(base_url)
                parsed_joined = urlparse(joined_url)
                # ูุชุฃูุฏ ุฃู ุงูุฑุงุจุท ุฏุงุฎูู (ููุณ ุงูุฏูููู)
                if parsed_base.netloc == parsed_joined.netloc:
                    if joined_url not in visited and joined_url not in to_visit:
                        to_visit.append(joined_url)

        except Exception as e:
            print(f"โ Error visiting {url}: {e}")
            continue

    # ุฏูุฌ ูู ุงููุตูุต ุงููุณุชุฎุฑุฌุฉ
    combined_text = "\n\n---\n\n".join(all_texts)
    return combined_text


def load_examples_from_json(json_path="example_profiles.json"):
    with open(json_path, "r", encoding="utf-8") as f:
        return json.load(f)


'''def generate_profile_model(data, examples):

    client = OpenAI(api_key=api_key)
    examples_text = "\n\n".join(examples[:2])  # ูุฑุณู ุฃูู ูุซุงููู ููุท ูุชูููู ุงูุทูู
    prompt=f"""
ุฃูุช ุฎุจูุฑ ูุญุชุฑู ูู ุฅุนุฏุงุฏ ุงููููุงุช ุงูุชุนุฑูููุฉ ููุดุฑูุงุช (Company Profiles)ุ ูุชุนูู ููุณุชุดุงุฑ ุงุณุชุฑุงุชูุฌู ูุชุทููุฑ ุงููููุฉ ุงููุคุณุณูุฉ ูุตูุงุบุฉ ุงููุญุชูู ุงูุชุณูููู ุงูุงุญุชุฑุงูู.

ุณุชุชููู:
- ุฃูุซูุฉ ุญููููุฉ ููููุงุช ุชุนุฑูููุฉ ูุงุฌุญุฉ ูุนุฏุฉ ุดุฑูุงุช:
{examples_text}

ููุนูููุงุช ุฃุณุงุณูุฉ ุชู ุงุณุชุฎุฑุงุฌูุง ูุจุงุดุฑุฉู ูู ูููุน ุงูุดุฑูุฉ (URL):
{data}

---

๐ ุงููุทููุจ ููู:
1๏ธโฃ ุชุญููู ุงูุฃูุซูุฉ ุงููุงุฑุฏุฉ ูุงุณุชุฎูุงุต ุฃุณููุจ ุงุญุชุฑุงูู ูุชูุงูู ูู ูุชุงุจุฉ ุงููููุงุช ุงูุชุนุฑูููุฉ.
2๏ธโฃ ุงูุงุณุชูุงุฏุฉ ูู ุงูุจูุงูุงุช ุงููุณุชุฎุฑุฌุฉ ูู ุงููููุน (url) ููุง ูู ุชูุงููุงุ ูุฅู ูู ุชูู ุงููุนูููุงุช ููุชููุฉุ ูู ุจุฅููุงููุง ูุงุจุชูุงุฑ ูุญุชูู ูููู ุจุฃุณููุจ ูุชูุงุณู.
3๏ธโฃ ูุชุงุจุฉ ููู ุชุนุฑููู ูุชูุงูู ูุดูู:
   - ูู ูุญู
   - ุงูุฑุคูุฉ (ูู ููุฑุฉ ูููุตูุฉ)
   - ุงูุฑุณุงูุฉ (ูู ููุฑุฉ ูููุตูุฉ)
   - ูุง ุงูุฐู ูููุฏูู
   - ููุงุฐุง ูุญู
   - ุฃุนูุงููุง
   - ุฎุฏูุงุชูุง (ููุตูุฉ ุจููุงุท)
   - ุฃุณููุจูุง
   - ูุนูููุงุช ุงูุชูุงุตู

---

โ ุชุนูููุงุช ุฃุณุงุณูุฉ:
- ุงุณุชุฎุฏู ุฃุณููุจ ุนุตุฑู ูุฌุฐุงุจ ููุงุฒู ุจูู ุงููุต ุงูุชุณูููู ูุงููุนูููุงุชู.
- ูุง ุชุนุชูุฏ ุนูู ูููู ุฌุงูุฒ ุญุฑูููุงุ ุงุจุชูุฑ ุชุฑุชูุจูุง ุชุฏุฑูุฌููุง ููุงุณุจ ูุฌุงู ุงูุดุฑูุฉ.
- ุงุฌุนู ุงููุต ุบูููุง ุจุงูุชูุงุตูู ููุนูุณ ุงููููุฉ ุงูุชูุงูุณูุฉ ุงููุณุชุฎูุตุฉ ูู ุงูุฃูุซูุฉ.
- ุงุณุชุฎุฏู ูุบุฉ ูุคุณุณูุฉ ุณูุณุฉ ููุชูุงุณูุฉ ุจุตุฑููุง ููุถูููููุง.
- ุงูุชุฑุถ ุฃู ุงูููู ุณููุณุชุฎุฏู ููุทุจุงุนุฉ ุงููุงุฎุฑุฉ ูุงูุนุฑูุถ ุงูุฅููุชุฑูููุฉ ูุงูุชูุฏูููุฉ.
- ุงูููู ูุฌุจ ุฃู ููุฌุณูุฏ ูููุฉ ุงูุดุฑูุฉ ููููุน ุงูุฌูุงุช ุงูุงุณุชุซูุงุฑูุฉ ูุงูุนููุงุก ุงููุณุชูุฏููู.

---

โจ ุงููุฏู:
ุฅูุดุงุก ููู ุชุนุฑููู ููู ูุนุจุฑ ุนู ุฑูุญ ุงูุดุฑูุฉ ุจุฃุณููุจ ูุณุชูุญู ููุชุนูููู ูู ุงูุฃูุซูุฉ ุงููุงุฑุฏุฉุ ูุน ููุก ุฃู ููุต ูู ุจูุงูุงุช ุงููููุน ุชููุงุฆููุง ุจุฃุณููุจ ุงุญุชุฑุงูู.
"""


    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "user", "content": prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content'''

@app.get("/profile-url/{user_id}/")
def profile_from_url(user_id: int,url: str = Query(..., description="Company website URL") ):
    #try:
    if not url or not url.startswith("http"):
        raise HTTPException(status_code=400, detail="Invalid URL")
    print (user_id)
    # ุงุณุชุฎุฑุฌ ุงูุจูุงูุงุช ูู ุงูุฑุงุจุท
    extracted_data = extract_info_from_url_and_subpages(url)

    # ููุฑุฃ ุงูุฃูุซูุฉ
    loaded_examples = load_examples_from_json()

    # ุชูููุฏ ุงูุจุฑููุงูู
    #generated_profile = generate_profile_model(extracted_data, loaded_examples)
    #print(generated_profile)

    try:
        #response = call_openai_api_with_retry(extracted_data,loaded_examples)
        #generated_profile = response.choices[0].message.content
        generated_profile = "The result will be here "
        input_type='Using URL'
        #  ุชุญูุธู ูู db 
        save_data= insert_generated_profile(user_id,None,generated_profile,input_type)
        return {"profile": response.choices[0].message.content}
    except HTTPException as e:
        raise e  # Forward HTTPException errors (e.g., rate limits)
    
    #input_type='Using URL'
    #  ุชุญูุธู ูู db 
    #save_data= insert_generated_profile(user_id,None,generated_profile,input_type)
    #return JSONResponse(content={"profile": generated_profile}, status_code=200,  media_type="application/json")
    # ุชุฑุณูู  ูููุงุฌูุฉ
    #return {"profile": generated_profile}
    
    #except Exception as e:
        #log and return a useful message
        #return JSONResponse(content={"error": str(e)}, status_code=500)
